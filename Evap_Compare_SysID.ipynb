{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newell-Lee Evaporator: Comparison of SysID Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Libraries for Pyomo\n",
    "from pyomo.environ import *\n",
    "from pyomo.dae import DerivativeVar, ContinuousSet\n",
    "\n",
    "# Libraries for MKCVA and CVA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.optimize import minimize\n",
    "from matplotlib import cm, colors\n",
    "from scipy.linalg import cholesky\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cyipopt\n",
    "import pickle\n",
    "\n",
    "# Libraries for LSTM\n",
    "import gc\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, LSTM\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from tensorflow.keras.models import Model,load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVA:\n",
    "    def __init__(self, verbose=None):\n",
    "        if verbose == None:\n",
    "            self.verbose = 0\n",
    "        else:\n",
    "            self.verbose = verbose\n",
    "    \n",
    "    def identify(self, Z_train, UI, YI, n_states=None):\n",
    "        \n",
    "        start = time()\n",
    "        self.UI = UI  # Column indices of input vars \n",
    "        self.YI = YI  # Column indices of output vars\n",
    "        N = Z_train.shape[0]\n",
    "\n",
    "        # Perform Standard Scaling on raw data [u y]\n",
    "        sc_raw = StandardScaler()\n",
    "        Z_train_sc = sc_raw.fit_transform(Z_train)\n",
    "        y_train = Z_train_sc[:, YI]\n",
    "        self.sc_raw = sc_raw\n",
    "\n",
    "        # Calculate the suggested no. of lags on the KPCA scores\n",
    "        _, ci = sm.tsa.acf(np.sum(y_train ** 2, axis=1), alpha=0.05)\n",
    "        self.n_lags = np.argwhere(ci[:,0] < 0)[0][0]\n",
    "        p = f = self.n_lags\n",
    "        \n",
    "        # Create Hankel matrices: Yp and Yf from KPCA scores\n",
    "        Yp, Yf = [], []\n",
    "        for k in np.arange(N-p-f):\n",
    "            Yp.append(np.flip(Z_train_sc[k:k+p, :].reshape(-1, 1)))\n",
    "\n",
    "        for k in np.arange(1, N-p-f+1):\n",
    "            Yf.append(Z_train_sc[k+p:k+p+f, YI].reshape(-1, 1))\n",
    "\n",
    "        Yp = np.transpose(np.hstack(Yp))\n",
    "        Yf = np.transpose(np.hstack(Yf))\n",
    "        Np = Yp.shape[0]\n",
    "\n",
    "        # Standardize the Hankel matrices\n",
    "        sc_p = StandardScaler()\n",
    "        sc_f = StandardScaler()\n",
    "        Yp_scaled = sc_p.fit_transform(Yp)\n",
    "        Yf_scaled = sc_f.fit_transform(Yf)\n",
    "        self.sc_p = sc_p\n",
    "\n",
    "        # Perform CCA\n",
    "        Epp = cholesky(np.dot(Yp_scaled.T, Yp_scaled))  # Past Cholesky matrix\n",
    "        Eff = cholesky(np.dot(Yf_scaled.T, Yf_scaled))  # Future Cholesky matrix\n",
    "        Efp = np.dot(Yf_scaled.T, Yp_scaled)            # Cross-covariance matrix\n",
    "        H = np.linalg.inv(Eff.T) @ Efp @ np.linalg.inv(Epp)\n",
    "\n",
    "        U, S, V = np.linalg.svd(H)\n",
    "\n",
    "        # Calculate the suggested no. of states via knee of SV plot\n",
    "        if n_states == None:\n",
    "            n_states = np.minimum(2 + np.argmax(np.diff(np.diff(S))), 10)\n",
    "        self.n_states = n_states\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f'No. of lags: {self.n_lags}')\n",
    "            plt.plot(np.arange(15)+1, S[:15], 'b.--')\n",
    "            plt.scatter(n_states, S[n_states-1], c='r')\n",
    "            plt.title('Singular Values plot')\n",
    "            print(f'No. of states: {n_states}')\n",
    "            plt.grid()\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        # Calculate the state vectors, X\n",
    "        Vn = np.transpose(V[:n_states, :])\n",
    "        Jn = np.dot(Vn.T, np.linalg.inv(Epp.T))\n",
    "        X = Jn @ Yp_scaled.T\n",
    "        self.Jn = Jn\n",
    "        \n",
    "        # Solve for A, B, C, D, K\n",
    "        M = X.shape[1]\n",
    "        tk = np.transpose(Z_train_sc[p-1:p+M-1, self.UI])\n",
    "        yk = np.transpose(y_train[p:p+M, :])\n",
    "\n",
    "        CD = yk[:,:(M-1)] @ np.linalg.pinv(np.vstack((X[:,:(M-1)], \n",
    "                                                      tk[:,:(M-1)])))\n",
    "        C = CD[:len(YI), :n_states]          # Output matrix\n",
    "        D = CD[:len(YI), n_states:]          # Feedthrough matrix\n",
    "\n",
    "        E = yk[:,:(M-1)] - C @ X[:,:(M-1)] - D @ tk[:,:(M-1)]\n",
    "        ABK = X[:,1:M] @ np.linalg.pinv(np.vstack((X[:,:(M-1)], \n",
    "                                                   tk[:,:(M-1)], E)))\n",
    "        A = ABK[:,:n_states]                 # State transition matrix\n",
    "        B = ABK[:,n_states:(n_states+len(UI))]  # Input matrix\n",
    "        K = ABK[:,(n_states+len(UI)):]          # Kalman gain\n",
    "        \n",
    "        self.ident_time = time() - start     # Time elapsed for identification\n",
    "        \n",
    "        self.A, self.B, self.C, self.D, self.K = A, B, C, D, K\n",
    "        self.X = X\n",
    "       \n",
    "    def init_sim(self, Z_test_sc):\n",
    "        # Calculate initial state x(0) using CVA projection matrix\n",
    "        yp = np.flip(Z_test_sc[:self.n_lags, :].reshape(1, -1))\n",
    "        Yp_scaled = self.sc_p.transform(yp)\n",
    "        x0 = self.Jn @ Yp_scaled.T\n",
    "        return x0\n",
    "    \n",
    "    def simulate(self, Z_test):\n",
    "        start = time()\n",
    "        Nt = Z_test.shape[0]\n",
    "        Z_test_sc = self.sc_raw.transform(Z_test)\n",
    "        x_pred = np.zeros((self.n_states, Nt - self.n_lags + 1)) \n",
    "        y_pred = np.zeros((len(self.YI), Nt - self.n_lags + 1))\n",
    "        x0 = self.init_sim(Z_test_sc)\n",
    "        u0 = Z_test_sc[0, self.UI].reshape(-1, 1)\n",
    "        y0 = self.C @ x0 + self.D @ u0\n",
    "        x_pred[:, 0] = x0.ravel()\n",
    "        y_pred[:, 0] = y0.ravel()\n",
    "        exit_code = 0\n",
    "        \n",
    "        for j in np.arange(1, y_pred.shape[1]):\n",
    "            uk = Z_test_sc[j+self.n_lags-1, self.UI].reshape(-1, 1)\n",
    "            xk_1 = x_pred[:, j-1].reshape(-1, 1)\n",
    "            xk = self.A @ xk_1 + self.B @ uk\n",
    "            yk = self.C @ xk + self.D @ uk\n",
    "            x_pred[:, j] = xk.ravel()\n",
    "            y_pred[:, j] = yk.ravel()\n",
    "            if (np.abs(yk) > 1e3).any():\n",
    "                exit_code = -1\n",
    "        \n",
    "        x_pred = np.transpose(x_pred)\n",
    "        y_pred = np.transpose(y_pred)\n",
    "        y_pred = (y_pred * self.sc_raw.scale_[self.YI]) + \\\n",
    "                           self.sc_raw.mean_[self.YI]\n",
    "        self.sim_time = time() - start\n",
    "        \n",
    "        return x_pred, y_pred, exit_code\n",
    "    \n",
    "    def R2_score(self, Z_test, y_pred):\n",
    "        r2 = np.zeros(len(self.YI))\n",
    "        for k in range(len(self.YI)):\n",
    "            y_true = Z_test[self.n_lags-1:, self.YI[k]]\n",
    "            r2[k] = 1 - np.sum((y_true - y_pred[:, k]) ** 2) \\\n",
    "                    / np.sum((y_true - np.mean(y_true)) ** 2)   \n",
    "        return r2\n",
    "    \n",
    "    def display(self):\n",
    "        print(f'No. of lags: {self.n_lags}')\n",
    "        print(f'No. of states: {self.n_states}')\n",
    "        print(f'Indices of u: {self.UI}')\n",
    "        print(f'Indices of y: {self.YI}')\n",
    "        print('State-space matrices:')\n",
    "        print(self.A)\n",
    "        print(self.B)\n",
    "        print(self.C)\n",
    "        print(self.D)\n",
    "        print(self.K)\n",
    "        \n",
    "class KPCA:\n",
    "    def kernel_func(self, x1, x2):\n",
    "        # x1 size: [no. of samples x no. of features]\n",
    "        # x2 size: [no. of samples x no. of features]\n",
    "        \n",
    "        D = np.sum((x1 / self.kw) ** 2, axis=1, keepdims=True) \\\n",
    "            + np.sum((x2 / self.kw).T ** 2, axis=0, keepdims=True) \\\n",
    "            - 2 * np.tensordot(x1 / self.kw**2, x2.T, axes=1)\n",
    "        L = np.tensordot(x1, x2.T, axes=1) + 1\n",
    "        return self.w * L + (1 - self.w) * np.exp(-D)\n",
    "        \n",
    "    def fit_transform(self, X, kw, w, n_comp=None):\n",
    "        # Compute kernel matrix\n",
    "        self.X = X\n",
    "        self.kw = kw\n",
    "        self.w = w\n",
    "        self.N = len(self.X)\n",
    "        \n",
    "        # Calculate reduced kernel matrix with k-medoids clustering \n",
    "        dist = pairwise_distances(self.X)\n",
    "        dm = kmedoids.KMedoids(method='fasterpam', \n",
    "                               n_clusters=int(0.2*self.N), \n",
    "                               random_state=0).fit(dist)\n",
    "        self.X_red = X[dm.medoid_indices_, :]\n",
    "        self.N_red = len(dm.medoid_indices_)\n",
    "        self.medoid_indices = dm.medoid_indices_\n",
    "        self.K = self.kernel_func(self.X_red, self.X_red)\n",
    "\n",
    "        # Center the kernel matrix\n",
    "        self.U = np.ones((self.N_red, self.N_red)) / self.N_red\n",
    "        Kc = self.K - self.U @ self.K - self.K @ self.U + self.U @ self.K @ self.U\n",
    "\n",
    "        # Perform eigenvalue decomposition\n",
    "        eigvals, eigvecs = np.linalg.eigh(Kc / self.N_red)\n",
    "\n",
    "        # Ensure the eigenvalues are sorted in decreasing order\n",
    "        ind = (-eigvals).argsort()\n",
    "        eigvals = eigvals[ind]\n",
    "        eigvecs = eigvecs[:,ind]\n",
    "        \n",
    "        if n_comp == None:\n",
    "            # Get eigenvalues using CPV = 99%\n",
    "            CPV = np.cumsum(eigvals) / np.sum(eigvals)\n",
    "            self.n_comp = np.argwhere(CPV > 0.99)[0][0]\n",
    "        else:\n",
    "            self.n_comp = n_comp\n",
    "        \n",
    "        self.CPV = CPV\n",
    "        \n",
    "        # Compute the projection matrix\n",
    "        self.P = eigvecs[:,:self.n_comp] @ np.diag(eigvals[:self.n_comp] ** -0.5)\n",
    "        \n",
    "        # Project the training data X via the reduced centered kernel matrix\n",
    "        scores = self.transform(self.X)\n",
    "        return scores\n",
    "    \n",
    "    def transform(self, Xt):\n",
    "        if len(Xt.shape) == 1:\n",
    "            Xt = Xt.reshape(1, -1)\n",
    "        \n",
    "        Kt = np.transpose(self.kernel_func(self.X_red, Xt))\n",
    "        Ut = np.ones((Xt.shape[0], self.N_red)) / self.N_red\n",
    "        Kct = Kt - Ut @ self.K - Kt @ self.U + Ut @ self.K @ self.U\n",
    "        scores = Kct @ self.P\n",
    "        return scores\n",
    "    \n",
    "class MKCVA:\n",
    "    def __init__(self, verbose=None):\n",
    "        if verbose == None:\n",
    "            self.verbose = 0\n",
    "        else:\n",
    "            self.verbose = verbose\n",
    "    \n",
    "    def identify(self, Z_train, UI, YI, kw=None, w=None, n_states=None):\n",
    "        \n",
    "        start = time()\n",
    "        self.UI = UI  # Column indices of input vars \n",
    "        self.YI = YI  # Column indices of output vars\n",
    "        N = Z_train.shape[0]\n",
    "\n",
    "        # Perform Standard Scaling on raw data [u y]\n",
    "        sc_raw = StandardScaler()\n",
    "        Z_train_sc = sc_raw.fit_transform(Z_train)\n",
    "        y_train = Z_train_sc[:, YI]\n",
    "        self.sc_raw = sc_raw\n",
    "\n",
    "        # Perform KPCA on scaled [u(k), y(k-1)] data\n",
    "        \n",
    "        Z_kpca = np.hstack((Z_train_sc[1:, self.UI], \n",
    "                            Z_train_sc[:-1, self.YI]))\n",
    "        \n",
    "        kpca_uy = KPCA()\n",
    "        kpca_score_uy = kpca_uy.fit_transform(Z_kpca, kw, w)\n",
    "        self.kpca_uy = kpca_uy\n",
    "        \n",
    "        # Perform KPCA on scaled [y] data\n",
    "        kpca_y = KPCA()\n",
    "        kw = kpca_uy.kw * (len(YI) / Z_train.shape[1])\n",
    "        kpca_score_y = kpca_y.fit_transform(Z_train_sc[:,YI], kw[YI], w)\n",
    "        N_uy, N_y = kpca_uy.n_comp, kpca_y.n_comp\n",
    "\n",
    "        # Calculate the suggested no. of lags on the KPCA scores\n",
    "        _, ci = sm.tsa.acf(np.sum(kpca_score_y ** 2, axis=1), alpha=0.05)\n",
    "        self.n_lags = np.argwhere(ci[:,0] < 0)[0][0]\n",
    "        p = f = self.n_lags\n",
    "        \n",
    "        # Create Hankel matrices: Yp and Yf from KPCA scores\n",
    "        Yp, Yf, Yp_all = [], [], []\n",
    "        for k in np.arange(N-p-f):\n",
    "            Yp.append(np.flip(kpca_score_uy[k:k+p, :].reshape(-1, 1)))\n",
    "\n",
    "        for k in np.arange(1, N-p-f+1):\n",
    "            Yf.append(kpca_score_y[k+p:k+p+f, :].reshape(-1, 1))\n",
    "\n",
    "        Yp = np.transpose(np.hstack(Yp))\n",
    "        Yf = np.transpose(np.hstack(Yf))\n",
    "        Np = Yp.shape[0]\n",
    "\n",
    "        # Standardize the Hankel matrices\n",
    "        sc_p = StandardScaler()\n",
    "        sc_f = StandardScaler()\n",
    "        Yp_scaled = sc_p.fit_transform(Yp)\n",
    "        Yf_scaled = sc_f.fit_transform(Yf)\n",
    "        self.sc_p = sc_p\n",
    "\n",
    "        # Perform CCA\n",
    "        Epp = cholesky(np.dot(Yp_scaled.T, Yp_scaled))  # Past Cholesky matrix\n",
    "        Eff = cholesky(np.dot(Yf_scaled.T, Yf_scaled))  # Future Cholesky matrix\n",
    "        Efp = np.dot(Yf_scaled.T, Yp_scaled)            # Cross-covariance matrix\n",
    "        H = np.linalg.inv(Eff.T) @ Efp @ np.linalg.inv(Epp)\n",
    "\n",
    "        U, S, V = np.linalg.svd(H)\n",
    "\n",
    "        # Calculate the suggested no. of states via knee of SV plot\n",
    "        if n_states == None:\n",
    "            n_states = np.minimum(2 + np.argmax(np.diff(np.diff(S))), 10)\n",
    "        self.n_states = n_states\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f'No. of KPCs on [u y]: {N_uy}')\n",
    "            print(f'No. of KPCs on [y]:   {N_y}')\n",
    "            print(f'No. of lags: {self.n_lags}')\n",
    "            plt.figure(figsize=(12, 3))\n",
    "            plt.subplot(131)\n",
    "            plt.title('CPV Plot for KPCA on [u y]')\n",
    "            plt.plot(np.arange(len(kpca_uy.CPV))+1, kpca_uy.CPV, 'b.--')\n",
    "            plt.scatter(kpca_uy.n_comp, kpca_uy.CPV[kpca_uy.n_comp-1], c='r')\n",
    "            plt.xlim([0, 30])\n",
    "            plt.grid()\n",
    "            plt.subplot(132)\n",
    "            plt.title('CPV Plot for KPCA on [y]')\n",
    "            plt.plot(np.arange(len(kpca_y.CPV))+1, kpca_y.CPV, 'b.--')\n",
    "            plt.scatter(kpca_y.n_comp, kpca_y.CPV[kpca_y.n_comp-1], c='r')\n",
    "            plt.xlim([0, 30])\n",
    "            plt.grid()\n",
    "            plt.subplot(133)\n",
    "            plt.plot(np.arange(15)+1, S[:15], 'b.--')\n",
    "            plt.scatter(n_states, S[n_states-1], c='r')\n",
    "            plt.title('Singular Values plot')\n",
    "            print(f'No. of states: {n_states}')\n",
    "            plt.grid()\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        # Calculate the state vectors, X\n",
    "        Vn = np.transpose(V[:n_states, :])\n",
    "        Jn = np.dot(Vn.T, np.linalg.inv(Epp.T))\n",
    "        X = Jn @ Yp_scaled.T\n",
    "        self.Jn = Jn\n",
    "        \n",
    "        # Solve for A, B, C, D, K\n",
    "        M = X.shape[1]\n",
    "        tk = np.transpose(kpca_score_uy[p-1:p+M-1, :])\n",
    "        yk = np.transpose(y_train[p:p+M, :])\n",
    "\n",
    "        CD = yk[:,:(M-1)] @ np.linalg.pinv(np.vstack((X[:,:(M-1)], \n",
    "                                                      tk[:,:(M-1)])))\n",
    "        C = CD[:len(YI), :n_states]          # Output matrix\n",
    "        D = CD[:len(YI), n_states:]          # Feedthrough matrix\n",
    "\n",
    "        E = yk[:,:(M-1)] - C @ X[:,:(M-1)] - D @ tk[:,:(M-1)]\n",
    "        ABK = X[:,1:M] @ np.linalg.pinv(np.vstack((X[:,:(M-1)], \n",
    "                                                   tk[:,:(M-1)], E)))\n",
    "        A = ABK[:,:n_states]                 # State transition matrix\n",
    "        B = ABK[:,n_states:(n_states+N_uy)]  # Input matrix\n",
    "        K = ABK[:,(n_states+N_uy):]          # Kalman gain\n",
    "        \n",
    "        self.ident_time = time() - start     # Time elapsed for identification\n",
    "        \n",
    "        self.A, self.B, self.C, self.D, self.K = A, B, C, D, K\n",
    "        self.X = X\n",
    "       \n",
    "    def init_sim(self, Z_test_sc):\n",
    "        # Calculate initial state x(0) using CVA projection matrix\n",
    "        tk = self.kpca_uy.transform(Z_test_sc)\n",
    "        tk_p = np.flip(tk[:self.n_lags, :].reshape(1, -1))\n",
    "        Yp_scaled = self.sc_p.transform(tk_p)\n",
    "        x0 = self.Jn @ Yp_scaled.T\n",
    "        t0 = tk[self.n_lags, :].reshape(-1, 1)\n",
    "        return x0, t0\n",
    "    \n",
    "    def simulate(self, Z_test):\n",
    "        start = time()\n",
    "        Nt = Z_test.shape[0]\n",
    "        Z_test_sc = self.sc_raw.transform(Z_test)\n",
    "        x_pred = np.zeros((self.n_states, Nt - self.n_lags + 1)) \n",
    "        y_pred = np.zeros((len(self.YI), Nt - self.n_lags + 1))\n",
    "        x0, t0 = self.init_sim(Z_test_sc)\n",
    "        y0 = self.C @ x0 + self.D @ t0\n",
    "        x_pred[:, 0] = x0.ravel()\n",
    "        y_pred[:, 0] = y0.ravel()\n",
    "        exit_code = 0\n",
    "        \n",
    "        for j in np.arange(1, y_pred.shape[1]):\n",
    "            zk = np.hstack((Z_test_sc[j+self.n_lags-1, self.UI], \n",
    "                            y_pred[:, j-1]))\n",
    "            tk = self.kpca_uy.transform(zk.reshape(1, -1))\n",
    "            xk_1 = x_pred[:, j-1].reshape(-1, 1)\n",
    "            xk = self.A @ xk_1 + self.B @ tk.T\n",
    "            yk = self.C @ xk + self.D @ tk.T\n",
    "            x_pred[:, j] = xk.ravel()\n",
    "            y_pred[:, j] = yk.ravel()\n",
    "            if (np.abs(yk) > 1e3).any():\n",
    "                exit_code = -1\n",
    "        \n",
    "        x_pred = np.transpose(x_pred)\n",
    "        y_pred = np.transpose(y_pred)\n",
    "        y_pred = (y_pred * self.sc_raw.scale_[self.YI]) + \\\n",
    "                           self.sc_raw.mean_[self.YI]\n",
    "        self.sim_time = time() - start\n",
    "        \n",
    "        return x_pred, y_pred, exit_code\n",
    "    \n",
    "    def R2_score(self, Z_test, y_pred):\n",
    "        r2 = np.zeros(len(self.YI))\n",
    "        for k in range(len(self.YI)):\n",
    "            y_true = Z_test[self.n_lags-1:, self.YI[k]]\n",
    "            r2[k] = 1 - np.sum((y_true - y_pred[:, k]) ** 2) \\\n",
    "                    / np.sum((y_true - np.mean(y_true)) ** 2)   \n",
    "        return r2\n",
    "    \n",
    "    def display(self):\n",
    "        print(f'No. of medoids: {self.kpca_uy.N_red}')\n",
    "        print(f'No. of KPCs on [u y]: {self.kpca_uy.n_comp}')\n",
    "        print(f'No. of lags: {self.n_lags}')\n",
    "        print(f'No. of states: {self.n_states}')\n",
    "        print(f'Indices of u: {self.UI}')\n",
    "        print(f'Indices of y: {self.YI}')\n",
    "        print('State-space matrices:')\n",
    "        print(self.A)\n",
    "        print(self.B)\n",
    "        print(self.C)\n",
    "        print(self.D)\n",
    "        print(self.K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cva_mdl = pickle.load(open('evap_cva_sys.pkl','rb'))\n",
    "mkcva_mdl = pickle.load(open('evap_mkcva_sys3.pkl','rb'))\n",
    "lstm_mdl = load_model('evap_lstm.keras')\n",
    "\n",
    "look_back = 15\n",
    "YI, UI = np.array([3, 4, 5]), np.array([0, 1, 2])\n",
    "input_spec = tf.TensorSpec([None, look_back, len(UI)+len(YI)], dtype=tf.float32)\n",
    "lstm_func = tf.function(lstm_mdl).get_concrete_function(input_spec)\n",
    "\n",
    "# Use Tensorflow's XLA (Accelerated Linear Algebra) for faster inference\n",
    "@tf.function(jit_compile=True)\n",
    "def lstm_predict(x):\n",
    "    return lstm_func(tf.cast(x, tf.float32))\n",
    "\n",
    "# Standardscaler params of original Training Data (for LSTM use only)\n",
    "scale_ = np.array([30.52634951, 27.30680801, 3.31043849, 0.12226375, 2.27643356, 4.95861316])\n",
    "mean_ = np.array([204.82968912, 196.14955658, 49.74290531, 1.0075573, 50.58551774, 25.41497448])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods for evaluating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(evap_df):\n",
    "    noise_var = np.array([0, 0, 0, 0.1, 1, 1])\n",
    "    v_name = ['F200', 'P100', 'F3', 'L2', 'P2', 'X2']\n",
    "    timepts = np.linspace(0, 1000, 1001)\n",
    "    res = list()\n",
    "    for j in range(len(noise_var)):\n",
    "        data = np.interp(timepts, evap_df.index.values, evap_df[v_name[j]].values)\n",
    "        data += (np.random.rand(len(data))-0.5)*noise_var[j]\n",
    "        res.append(data)\n",
    "    \n",
    "    return np.transpose(np.vstack(res))\n",
    "\n",
    "def eval_pred(Z, y_pred):\n",
    "    r2 = np.zeros(len(YI))\n",
    "    for k in range(len(YI)):\n",
    "        y_true = Z[-len(y_pred):, YI[k]]\n",
    "        r2[k] = 1 - np.sum((y_true - y_pred[:, k]) ** 2) \\\n",
    "                / np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    \n",
    "    return r2\n",
    "\n",
    "def eval_CVA_onestep(Z):\n",
    "    start = time()\n",
    "    Nt = Z.shape[0]\n",
    "    Z_sc = cva_mdl.sc_raw.transform(Z)\n",
    "    uk = Z_sc[:, UI]\n",
    "    Yp = []\n",
    "    for k in np.arange(Nt-cva_mdl.n_lags*2):\n",
    "        Yp.append(np.flip(Z_sc[k:k+cva_mdl.n_lags, :].reshape(-1, 1)))\n",
    "        \n",
    "    Yp_scaled = cva_mdl.sc_p.transform(np.transpose(np.hstack(Yp)))\n",
    "    x_pred = cva_mdl.Jn @ Yp_scaled.T\n",
    "    y_pred = []\n",
    "    for j in range(x_pred.shape[1]):\n",
    "        y_pred.append(cva_mdl.C @ x_pred[:, j] + cva_mdl.D @ uk[cva_mdl.n_lags+j, :].T) \n",
    "        \n",
    "    y_pred = np.vstack(y_pred) * cva_mdl.sc_raw.scale_[YI] + cva_mdl.sc_raw.mean_[YI]\n",
    "    sim_time = time() - start\n",
    "    \n",
    "    r2 = eval_pred(Z[:-look_back, :], y_pred)\n",
    "    return r2, sim_time\n",
    "\n",
    "def eval_CVA_simulate(Z):\n",
    "    sim_time = time()\n",
    "    x_pred, y_pred, exit_code = cva_mdl.simulate(Z)\n",
    "    sim_time = time() - sim_time\n",
    "    r2 = eval_pred(Z, y_pred)\n",
    "    return r2, sim_time\n",
    "\n",
    "def eval_MKCVA_onestep(Z):\n",
    "    sim_time = time()\n",
    "    Nt = Z.shape[0]\n",
    "    Z_sc = mkcva_mdl.sc_raw.transform(Z)\n",
    "    Z_kpca = np.hstack((Z_sc[1:, UI],\n",
    "                        Z_sc[:-1, YI]))\n",
    "    tk = mkcva_mdl.kpca_uy.transform(Z_kpca)\n",
    "    Yp = []\n",
    "    for k in np.arange(Nt-mkcva_mdl.n_lags*2):\n",
    "        Yp.append(np.flip(tk[k:k+mkcva_mdl.n_lags, :].reshape(-1, 1)))\n",
    "        \n",
    "    Yp_scaled = mkcva_mdl.sc_p.transform(np.transpose(np.hstack(Yp)))\n",
    "    x_pred = mkcva_mdl.Jn @ Yp_scaled.T\n",
    "    y_pred = []\n",
    "    for j in range(x_pred.shape[1]):\n",
    "        y_pred.append(mkcva_mdl.C @ x_pred[:, j] + mkcva_mdl.D @ tk[mkcva_mdl.n_lags+j, :].T) \n",
    "    \n",
    "    y_pred = np.vstack(y_pred) * mkcva_mdl.sc_raw.scale_[YI] + mkcva_mdl.sc_raw.mean_[YI]\n",
    "    sim_time = time() - sim_time\n",
    "    r2 = eval_pred(Z[:-look_back, :], y_pred)\n",
    "    return r2, sim_time\n",
    "\n",
    "def eval_MKCVA_simulate(Z):\n",
    "    sim_time = time()\n",
    "    x_pred, y_pred, exit_code = mkcva_mdl.simulate(Z)\n",
    "    sim_time = time() - sim_time\n",
    "    r2 = eval_pred(Z, y_pred)\n",
    "    return r2, sim_time\n",
    "\n",
    "def eval_LSTM_onestep(Z):\n",
    "    Z_sc = (Z - mean_) / scale_\n",
    "    UY_, Y_ = [], []\n",
    "\n",
    "    for k in range(1, len(Z)-look_back+1):\n",
    "        UY_.append(np.hstack((Z_sc[k:k+look_back, UI], \n",
    "                              Z_sc[k-1:k+look_back-1, YI])))\n",
    "\n",
    "    UY_ = np.stack(UY_, axis=0)\n",
    "\n",
    "    K.clear_session()\n",
    "    \n",
    "    sim_time = time()\n",
    "    y = lstm_predict(UY_)\n",
    "    y_pred = y[:, -1, :] * scale_[YI] + mean_[YI]\n",
    "    sim_time = time() - sim_time\n",
    "    r2 = eval_pred(Z, y_pred)\n",
    "    return r2, sim_time\n",
    "\n",
    "def eval_LSTM_simulate(Z):\n",
    "    start = time()\n",
    "    uy0 = Z[:look_back, :]\n",
    "    u = Z[look_back-1:, UI]\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    N = u.shape[0]\n",
    "    y_pred = np.zeros((N, len(YI)))\n",
    "    uy = (uy0 - mean_) / scale_\n",
    "    u_ = (u - mean_[UI]) / scale_[UI]\n",
    "    y_pred[0, :] = uy[-1, YI]\n",
    "    \n",
    "    for j in np.arange(1, N):\n",
    "        uy = np.hstack((np.vstack((uy[1:, UI], \n",
    "                                   u_[np.minimum(j, N), :])), \n",
    "                        uy[:, YI]))\n",
    "        y = lstm_predict(uy[np.newaxis, :, :])\n",
    "        y_pred[j, :] = y[:, -1, :]\n",
    "        uy = np.hstack((uy[:, UI],\n",
    "                        np.vstack((uy[1:, YI], y[:, -1, :]))))\n",
    "    \n",
    "    y_pred = y_pred * scale_[YI] + mean_[YI]\n",
    "    sim_time = time() - start\n",
    "    r2 = eval_pred(Z, y_pred)\n",
    "    return r2, sim_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Pyomo model and simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: The current pynumero_ASL library is version=3, but found version=1.\n",
      "Please recompile / update your pynumero_ASL library.\n",
      "Trial 0: [10.86 sec], OK? True\n",
      "Trial 1: [7.24 sec], OK? True\n",
      "Trial 2: [7.08 sec], OK? True\n",
      "Trial 3: [7.74 sec], OK? True\n",
      "Trial 4: [6.78 sec], OK? True\n",
      "Trial 5: [6.77 sec], OK? True\n",
      "Trial 6: [6.63 sec], OK? True\n",
      "Trial 7: [6.73 sec], OK? True\n",
      "Trial 8: [6.92 sec], OK? True\n",
      "Trial 9: [7.27 sec], OK? True\n",
      "Trial 10: [7.13 sec], OK? True\n",
      "Trial 11: [7.82 sec], OK? True\n",
      "Trial 12: [7.87 sec], OK? True\n",
      "Trial 13: [7.35 sec], OK? True\n",
      "Trial 14: [7.71 sec], OK? True\n",
      "Trial 15: [7.36 sec], OK? True\n",
      "Trial 16: [7.23 sec], OK? True\n",
      "Trial 17: [9.26 sec], OK? True\n",
      "Trial 18: [7.44 sec], OK? True\n",
      "Trial 19: [7.06 sec], OK? True\n",
      "Trial 20: [6.56 sec], OK? True\n",
      "Trial 21: [6.69 sec], OK? True\n",
      "Trial 22: [6.56 sec], OK? True\n",
      "Trial 23: [6.59 sec], OK? True\n",
      "Trial 24: [6.66 sec], OK? True\n",
      "Trial 25: [6.59 sec], OK? True\n",
      "Trial 26: [6.61 sec], OK? True\n",
      "Trial 27: [6.68 sec], OK? True\n",
      "Trial 28: [6.70 sec], OK? True\n",
      "Trial 29: [6.80 sec], OK? True\n",
      "Trial 30: [6.55 sec], OK? True\n",
      "Trial 31: [6.61 sec], OK? True\n",
      "Trial 32: [6.74 sec], OK? True\n",
      "Trial 33: [6.74 sec], OK? True\n",
      "Trial 34: [6.74 sec], OK? True\n",
      "Trial 35: [7.73 sec], OK? True\n",
      "Trial 36: [7.29 sec], OK? True\n",
      "Trial 37: [7.35 sec], OK? True\n",
      "Trial 38: [7.00 sec], OK? True\n",
      "Trial 39: [8.20 sec], OK? True\n",
      "Trial 40: [7.83 sec], OK? True\n",
      "Trial 41: [7.95 sec], OK? True\n",
      "Trial 42: [8.19 sec], OK? True\n",
      "Trial 43: [8.34 sec], OK? True\n",
      "Trial 44: [8.58 sec], OK? True\n",
      "Trial 45: [8.38 sec], OK? True\n",
      "Trial 46: [8.43 sec], OK? True\n",
      "Trial 47: [7.77 sec], OK? True\n",
      "Trial 48: [7.50 sec], OK? True\n",
      "Trial 49: [7.15 sec], OK? True\n",
      "   CVA-Pred-R2  CVA-Pred-Time  CVA-Sim-R2  CVA-Sim-Time  MKCVA-Pred-R2  \\\n",
      "0     0.952711       0.015621    0.863688      0.015621       0.957750   \n",
      "1     0.940857       0.000000    0.856599      0.025658       0.946141   \n",
      "2     0.953999       0.007953    0.869972      0.013771       0.956676   \n",
      "3     0.940505       0.015622    0.850698      0.015622       0.944953   \n",
      "4     0.954097       0.000000    0.839153      0.015665       0.956614   \n",
      "\n",
      "   MKCVA-Pred-Time  MKCVA-Sim-R2  MKCVA-Sim-Time  LSTM-Pred-R2  \\\n",
      "0         0.015595      0.915444        0.354894      0.949924   \n",
      "1         0.017215      0.900610        0.341315      0.941296   \n",
      "2         0.019633      0.912768        0.334538      0.957046   \n",
      "3         0.023718      0.896955        0.360684      0.941159   \n",
      "4         0.015578      0.894235        0.313628      0.952385   \n",
      "\n",
      "   LSTM-Pred-Time  LSTM-Sim-R2  LSTM-Sim-Time  \n",
      "0        3.965236     0.918661       1.141587  \n",
      "1        0.008977     0.920586       0.869305  \n",
      "2        0.008574     0.934622       1.068609  \n",
      "3        0.009531     0.914973       0.909939  \n",
      "4        0.015624     0.912614       0.848735  \n"
     ]
    }
   ],
   "source": [
    "def solve_model(ti, tf, F200data, P100data, F3data, init_data):\n",
    "\n",
    "    evap = ConcreteModel()\n",
    "\n",
    "    evap.ti = Param(initialize=ti)\n",
    "    evap.tf = Param(initialize=tf)\n",
    "    evap.t = ContinuousSet(bounds=(evap.ti,evap.tf))\n",
    "\n",
    "    # States\n",
    "    evap.L2 = Var(evap.t, initialize=1, bounds=(0, 4))\n",
    "    evap.P2 = Var(evap.t, initialize=50.5)\n",
    "    evap.X2 = Var(evap.t, initialize=25)\n",
    "\n",
    "    # Manipulated variable to control L2 via P-control\n",
    "    evap.F2 = Var(evap.t, initialize=2)\n",
    "    \n",
    "    # Inputs and Disturbances\n",
    "    evap.T200 = Param(evap.t, default=25)\n",
    "    evap.F1 = Param(evap.t, default=10)\n",
    "    evap.X1 = Param(evap.t, default=5)\n",
    "    evap.T1 = Param(evap.t, default=40)\n",
    "\n",
    "    evap.F200 = Param(evap.t, mutable=True)  # Input to be manipulated\n",
    "    evap.P100 = Param(evap.t, mutable=True)  # Input to be manipulated\n",
    "    evap.F3 = Param(evap.t, mutable=True)    # Input to be manipulated\n",
    "\n",
    "    # Other outputs\n",
    "    evap.F4 = Var(evap.t, initialize=8)\n",
    "    evap.F5 = Var(evap.t, initialize=8)\n",
    "    evap.T2 = Var(evap.t, initialize=84.6)\n",
    "    evap.T3 = Var(evap.t, initialize=80.6)\n",
    "    evap.F100 = Var(evap.t, initialize=9.27)\n",
    "    evap.T100 = Var(evap.t, initialize=119.9)\n",
    "    evap.Q100 = Var(evap.t, initialize=339.2)\n",
    "    evap.T201 = Var(evap.t, initialize=46.15)\n",
    "    evap.Q200 = Var(evap.t, initialize=308)\n",
    "\n",
    "    # Setup derivative vars for states\n",
    "    evap.dL2dt = DerivativeVar(evap.L2, initialize=init_data['dL2dt'])\n",
    "    evap.dP2dt = DerivativeVar(evap.P2, initialize=init_data['dP2dt'])\n",
    "    evap.dX2dt = DerivativeVar(evap.X2, initialize=init_data['dX2dt'])\n",
    "\n",
    "    # Set an objective\n",
    "    evap.obj = Objective(expr=1)\n",
    "\n",
    "    evap.z1dot = Constraint(evap.t, rule = lambda m, i: \\\n",
    "                           m.dL2dt[i]*20 == m.F1[i] - m.F4[i] - m.F2[i])\n",
    "    evap.z2dot = Constraint(evap.t, rule = lambda m, i: \\\n",
    "                           m.dX2dt[i]*20 == m.F1[i]*m.X1[i] - m.F2[i]*m.X2[i])\n",
    "    evap.z3dot = Constraint(evap.t, rule = lambda m, i: \\\n",
    "                           m.dP2dt[i]*4 == m.F4[i] - m.F5[i])\n",
    "\n",
    "    # Other constraints\n",
    "    evap.con1 = Constraint(evap.t, rule = lambda m, i: \\\n",
    "                          m.T2[i] == 0.5616*m.P2[i] + 0.3126*m.X2[i] + 48.43)\n",
    "    evap.con2 = Constraint(evap.t, rule = lambda m, i: \\\n",
    "                          m.T3[i] == 0.507*m.P2[i] + 55)\n",
    "    evap.con3 = Constraint(evap.t, rule = lambda m, i: \\\n",
    "                          m.F4[i]*38.5 == m.Q100[i] - 0.07*m.F1[i]*(m.T2[i] - m.T1[i]))\n",
    "    evap.con4 = Constraint(evap.t, rule = lambda m, i: \\\n",
    "                          m.T100[i] == 0.1538*m.P100[i] + 90)\n",
    "    evap.con5 = Constraint(evap.t, rule = lambda m, i: \\\n",
    "                          m.Q100[i] == 0.16*(m.F1[i] + m.F3[i])*(m.T100[i] - m.T2[i]))\n",
    "    evap.con6 = Constraint(evap.t, rule = lambda m, i: \\\n",
    "                          m.F100[i]*36.6 == m.Q100[i])\n",
    "    evap.con7 = Constraint(evap.t, rule = lambda m, i: \\\n",
    "                          m.Q200[i]*(0.14*m.F200[i]+6.84) == 0.9576*m.F200[i]*(m.T3[i]-m.T200[i]))\n",
    "    evap.con8 = Constraint(evap.t, rule = lambda m, i:\\\n",
    "                          m.T201[i] == m.T200[i] + m.Q200[i]/0.07/m.F200[i])\n",
    "    evap.con9 = Constraint(evap.t, rule = lambda m, i: \\\n",
    "                          m.F5[i]*38.5 == m.Q200[i])\n",
    "\n",
    "    def _init(m):\n",
    "        yield m.L2[evap.ti] == init_data['L2']\n",
    "        yield m.P2[evap.ti] == init_data['P2']\n",
    "        yield m.X2[evap.ti] == init_data['X2']\n",
    "    \n",
    "    evap.initcon = ConstraintList(rule=_init)\n",
    "\n",
    "    # Discretize using collocation\n",
    "    discretizer = TransformationFactory('dae.collocation')\n",
    "    discretizer.apply_to(evap, nfe=25, ncp=3, scheme='LAGRANGE-RADAU')\n",
    "\n",
    "    # P-controller\n",
    "    def _p_control(m, i):\n",
    "        if i > m.ti:\n",
    "            return m.F2[i] == 2 + 5*(m.L2[m.t.prev(i)] - 1.0)\n",
    "        else:\n",
    "            return m.F2[i] == init_data['F2']\n",
    "\n",
    "    evap.p_control = Constraint(evap.t, rule=_p_control)\n",
    "    \n",
    "    # Step change data\n",
    "    timepoints = list(evap.t)\n",
    "    if evap.ti.value == 0:\n",
    "        F200data[0] = 208\n",
    "        P100data[0] = 194.7\n",
    "        F3data[0] = 50\n",
    "    for i, t in enumerate(timepoints):\n",
    "        pos = np.argwhere(t>=i_data)[-1]\n",
    "        evap.F200[t] = F200data[pos][0]\n",
    "        evap.P100[t] = P100data[pos][0]\n",
    "        evap.F3[t] = F3data[pos][0]\n",
    "\n",
    "    # Solve using Pyomo IPOPT\n",
    "    solver = SolverFactory('cyipopt')\n",
    "    res = solver.solve(evap)\n",
    "    \n",
    "    model_vars = evap.component_map(ctype=Var)\n",
    "    model_params = evap.component_map(ctype=Param)\n",
    "\n",
    "    s_list = []\n",
    "    col_list = []\n",
    "    ctr = 1\n",
    "    for k in model_vars.keys():\n",
    "        v = model_vars[k]\n",
    "        s = pd.Series(v.extract_values(), \n",
    "                      index=v.extract_values().keys())\n",
    "        s.sort_index(inplace=True)\n",
    "        s_list.append(s)\n",
    "        col_list.append(v.name)\n",
    "        ctr += 1\n",
    "\n",
    "    for k in model_params.keys():\n",
    "        v = model_params[k]\n",
    "        if v.name == 'F200' or v.name == 'P100' or v.name == 'F3':\n",
    "            s = pd.Series(v.extract_values(), \n",
    "                          index=v.extract_values().keys())\n",
    "            s.sort_index(inplace=True)\n",
    "            s_list.append(s)\n",
    "            col_list.append(v.name)\n",
    "            ctr += 1\n",
    "\n",
    "    evap_df = pd.concat(s_list, axis=1)\n",
    "    evap_df.columns = col_list\n",
    "    return evap_df, res\n",
    "\n",
    "#rand_seed = 102\n",
    "#np.random.seed(rand_seed)\n",
    "i_data = np.arange(0, 1000, 50) # start, last, increment\n",
    "\n",
    "cva_pred_r2, cva_pred_time = [], []\n",
    "cva_sim_r2, cva_sim_time = [], []\n",
    "\n",
    "mkcva_pred_r2, mkcva_pred_time = [], []\n",
    "mkcva_sim_r2, mkcva_sim_time = [], []\n",
    "\n",
    "lstm_pred_r2, lstm_pred_time = [], []\n",
    "lstm_sim_r2, lstm_sim_time = [], []\n",
    "\n",
    "for trial in range(50):\n",
    "\n",
    "    # For extrapolation data (50% larger)\n",
    "    #F200data = (np.random.rand(i_data.shape[0])-0.5)*150 + 208\n",
    "    #P100data = (np.random.rand(i_data.shape[0])-0.5)*150 + 194.7\n",
    "    #F3data = (np.random.rand(i_data.shape[0])-0.5)*15 + 50\n",
    "\n",
    "    # For extrapolation data (25% larger)\n",
    "    #F200data = (np.random.rand(i_data.shape[0])-0.5)*125 + 208\n",
    "    #P100data = (np.random.rand(i_data.shape[0])-0.5)*125 + 194.7\n",
    "    #F3data = (np.random.rand(i_data.shape[0])-0.5)*12.5 + 50\n",
    "\n",
    "    # For interpolation data\n",
    "    F200data = (np.random.rand(i_data.shape[0])-0.5)*100 + 208\n",
    "    P100data = (np.random.rand(i_data.shape[0])-0.5)*100 + 194.7\n",
    "    F3data = (np.random.rand(i_data.shape[0])-0.5)*10 + 50\n",
    "\n",
    "    init_data = {'L2':1,    'P2':50.5, 'X2':25, 'F2':2,\n",
    "                 'dL2dt':0, 'dP2dt':0, 'dX2dt':0}\n",
    "\n",
    "    # Initialize the data frame\n",
    "    evap_df = pd.DataFrame(columns=['L2', 'P2', 'X2', 'dL2dt', 'dP2dt', \n",
    "                                    'dX2dt', 'F200', 'P100', 'F3'])\n",
    "\n",
    "    # Set the horizon length and total time\n",
    "    hor_len = 25\n",
    "    total_time = 1000\n",
    "    overall_status = True\n",
    "    sim_time = time()\n",
    "\n",
    "    for j in np.arange(0, total_time, hor_len): # start, last, increment\n",
    "\n",
    "        # Simulate the model at time [j, j+hor_len]\n",
    "        temp_df, res = solve_model(j, j+hor_len, F200data, P100data, F3data, init_data)\n",
    "        overall_status = overall_status and (res.Solver.status == 'ok')\n",
    "\n",
    "        # Save the last condition as the next initial condition\n",
    "        for k in init_data.keys():\n",
    "            init_data[k] = temp_df.iloc[-1][k]\n",
    "\n",
    "        # Append temp_df after evap_df\n",
    "        if j+hor_len < total_time:\n",
    "            evap_df = pd.concat([evap_df, temp_df.iloc[:-1,:]], axis=0)\n",
    "        else:\n",
    "            evap_df = pd.concat([evap_df, temp_df], axis=0)\n",
    "\n",
    "    sim_time = time() - sim_time\n",
    "    print(f'Trial {trial}: [{sim_time:.2f} sec], OK? {overall_status}')\n",
    "    \n",
    "    Z = prepare_data(evap_df)\n",
    "    r2, sim_time = eval_CVA_onestep(Z)\n",
    "    cva_pred_r2.append(np.mean(r2))\n",
    "    cva_pred_time.append(sim_time)\n",
    "    \n",
    "    r2, sim_time = eval_CVA_simulate(Z)\n",
    "    cva_sim_r2.append(np.mean(r2))\n",
    "    cva_sim_time.append(sim_time)\n",
    "\n",
    "    r2, sim_time = eval_MKCVA_onestep(Z)\n",
    "    mkcva_pred_r2.append(np.mean(r2))\n",
    "    mkcva_pred_time.append(sim_time)\n",
    "    \n",
    "    r2, sim_time = eval_MKCVA_simulate(Z)\n",
    "    mkcva_sim_r2.append(np.mean(r2))\n",
    "    mkcva_sim_time.append(sim_time)\n",
    "\n",
    "    r2, sim_time = eval_LSTM_onestep(Z)\n",
    "    lstm_pred_r2.append(np.mean(r2))\n",
    "    lstm_pred_time.append(sim_time)\n",
    "    \n",
    "    r2, sim_time = eval_LSTM_simulate(Z)\n",
    "    lstm_sim_r2.append(np.mean(r2))\n",
    "    lstm_sim_time.append(sim_time)\n",
    "\n",
    "df = pd.DataFrame(np.column_stack([cva_pred_r2, cva_pred_time, cva_sim_r2, cva_sim_time, mkcva_pred_r2, mkcva_pred_time, \n",
    "                  mkcva_sim_r2, mkcva_sim_time, lstm_pred_r2, lstm_pred_time, lstm_sim_r2, lstm_sim_time]),\n",
    "                  columns=['CVA-Pred-R2', 'CVA-Pred-Time', 'CVA-Sim-R2', 'CVA-Sim-Time', \n",
    "                           'MKCVA-Pred-R2', 'MKCVA-Pred-Time', 'MKCVA-Sim-R2', 'MKCVA-Sim-Time',\n",
    "                           'LSTM-Pred-R2', 'LSTM-Pred-Time', 'LSTM-Sim-R2', 'LSTM-Sim-Time'])\n",
    "print(df.head())\n",
    "df.to_csv('compare_sysID.csv', index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
